{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy基础\n",
    "大家好，这里是你们的第一个作业，即使你之前没有用过python，这个作业也会帮助你熟悉接下来会用到的功能\n",
    "\n",
    "操作指南:\n",
    "\n",
    "请使用python3\n",
    "避免使用for循环，除非题目里要求\n",
    "不要更改(# GRADED FUNCTION [function name])的注释\n",
    "写完代码，运行下面的cell确认你的输出是对的\n",
    "做完这个作业，你能学会：\n",
    "\n",
    "用ipython notebook\n",
    "用numpy，包括函数调用及向量矩阵运算\n",
    "理解“广播”的概念\n",
    "向量化代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    s = 1 / (1 + math.exp(-x))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(basic_sigmoid(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "math.exp不支持向量运算，只能输入常量。而np.exp可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    return s\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "\n",
    "print(basic_sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如你在教程中所看到的，我们需要计算梯度来使用反向传播优化损失函数。 让我们开始编写第一个梯度函数吧。\n",
    "\n",
    "练习：创建函数sigmoid_grad（）计算sigmoid函数相对于其输入x的梯度。 公式为：\n",
    "我们通常分两步编写此函数代码：\n",
    "1.计算s = sigmoid(x)\n",
    "2.计算ds = s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    return s\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    ds = s * (1 - s)\n",
    "    return ds\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "print(sigmoid_derivative(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习中两个常用的numpy函数是np.shape和np.reshape()。\n",
    "-X.shape用于获取矩阵/向量X的shape（维度）。\n",
    "-X.reshape（...）用于将X重塑为其他尺寸。\n",
    "\n",
    "例如，在计算机科学中，图像由shape为（length, height, depth = 3）的3 Dimension数组表示。但是，当你读取图像作为算法的输入时，会将其转换为维度为(length * height * 3, 1)的向量。换句话说，将3D阵列“展开”或重塑为1D向量。\n",
    "\n",
    "练习：实现image2vector() ,该输入采用维度为(length, height, 3)的输入，并返回维度为(length*height*3, 1)的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- a numpy array of shape (length, height, depth)\n",
    "    \n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    v = image.shape[0] * image.shape[1] * image.shape[2]\n",
    "    return image.reshape(v, 1)\n",
    "\n",
    "image = np.array([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "print (\"image2vector(image) = \" + str(image2vector(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4- 行标准化\n",
    "我们在机器学习和深度学习中使用的另一种常见技术是对数据进行标准化。(即线性代数求正交矩阵之前的单位化)\n",
    "练习：执行 normalizeRows（）来标准化矩阵的行。 将此函数应用于输入矩阵x之后，x的每一行应为单位长度（即长度为1）向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalizeRows(x):\n",
    "    \"\"\"\n",
    "    Implement a function that normalizes each row of the matrix x (to have unit length).\n",
    "    \n",
    "    Argument:\n",
    "    x -- A numpy matrix of shape (n, m)\n",
    "    \n",
    "    Returns:\n",
    "    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n",
    "\n",
    "    这里不能用/=, 否则会有类型转换异常。当x / x_norm(一个数)时，会进行广播，将x_norm扩展。\n",
    "    \"\"\"\n",
    "    x_norm = np.linalg.norm(x, axis = 1, keepdims = True)\n",
    "    #  axis = 0 对列求, = 1 对行求\n",
    "    x = x / x_norm\n",
    "    print(x_norm)\n",
    "    return x\n",
    "\n",
    "x = np.array([\n",
    "    [0, 3, 4],\n",
    "    [1, 6, 4]])\n",
    "print(\"normalizeRows(x) = \" + str(normalizeRows(x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5- 广播和softmax函数\n",
    "广播: 在不同形状的数组之间执行数学运算。\n",
    "softmax函数：需要对两个或多个类进行分类时使用的标准化函数。\n",
    "定义：\n",
    "    1）分子：通过指数函数，将实数输出映射到零到正无穷。（将每个元素作为e的幂次方，即将预测结果转化为非负数）\n",
    "    2）分母：将所有结果相加，进行归一化。（除以对应行的指数和，即归一化，各种预测结果概率之和等于1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Calculates the softmax for each row of the input x.\n",
    "\n",
    "    Your code should work for a row vector and also for matrices of shape (n, m).\n",
    "\n",
    "    Argument:\n",
    "    x -- A numpy matrix of shape (n,m)\n",
    "\n",
    "    Returns:\n",
    "    s -- A numpy matrix equal to the softmax of x, of shape (n,m)\n",
    "    \"\"\"\n",
    "    x_exp = np.exp(x)\n",
    "    x_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "    # axis=1对行进行求和，keepdims保持维度，此时为二行一列的矩阵，不然会变成(2,)的数组，出现奇怪错误，无法广播。\n",
    "    s = x_exp / x_sum\n",
    "    return s\n",
    "\n",
    "x = np.array([\n",
    "[9, 2, 5, 0, 0],\n",
    "[7, 5, 0, 0 ,0]])\n",
    "print(\"softmax(x) = \" + str(softmax(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-向量化：在深度学习中，通常需要处理非常大的数据集。 因此，非计算最佳函数可能会成为算法中的巨大瓶颈，并可能使模型运行一段时间。 为了确保代码的高效计算，我们将使用向量化。 例如，尝试区分点/外部/元素乘积之间的区别。\n",
    "不同于np.multiply()和* 操作符（相当于Matlab / Octave中的 .*）执行逐元素的乘法，np.dot()执行的是矩阵-矩阵或矩阵向量乘法\n",
    "用到的函数：\n",
    "    1. np.zeros(a, b) 创建维度为(a, b)的矩阵, 且每个元素初值为0\n",
    "    2. np.dot()执行的是矩阵-矩阵或矩阵向量乘法(——丨 = value)\n",
    "    3. time.process_time()获取当前微秒\n",
    "    4. np.outer(x1,x2)直接创建outer矩阵(丨 —— = matrix)\n",
    "    5. np.random.rand(a, b) 创建维度为(a, b)的矩阵, 随机值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION 计算矩阵 —— 丨 = value ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "for i in range(len(x1)):\n",
    "    dot+= x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### CLASSIC OUTER PRODUCT IMPLEMENTATION 计算 丨 —— = matrix ###\n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1),len(x2))) # we create a len(x1)*len(x2) matrix with only zeros\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i]*x2[j]\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### CLASSIC ELEMENTWISE IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "mul = np.zeros(len(x1))\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### CLASSIC GENERAL DOT PRODUCT IMPLEMENTATION ###\n",
    "W = np.random.rand(3,len(x1)) # Random 3*len(x1) numpy array\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j]*x1[j]\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(gdot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1实现L1和L2损失函数\n",
    "练习：实现L1损失函数的Numpy向量化版本。 我们会发现函数abs（x）（x的绝对值）很有用。\n",
    "\n",
    "提示：\n",
    "-损失函数用于评估模型的性能。 损失越大，预测(yhat) 与真实值(y)的差异也就越大。 在深度学习中，我们使用诸如Gradient Descent之类的优化算法来训练模型并最大程度地降低成本。\n",
    "-L1损失函数定义为：真实值-预测值的绝对值之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "    Arguments:\n",
    "    yhat -- vector of size m (predicted labels)\n",
    "    y -- vector of size m (true labels)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- the value of the L1 loss function defined above\n",
    "\"\"\"\n",
    "def L1(yhat, y):\n",
    "    loss = np.sum(np.abs(y - yhat))\n",
    "    return loss\n",
    "\n",
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \" + str(L1(yhat,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习：实现L2损失函数的Numpy向量化版本。 有好几种方法可以实现L2损失函数，但是还是np.dot（）函数更好用。 提醒一下，如果，x是向量矩阵，即x=[x1, x2, ...]则np.dot（x，x）= x的每个元素的平方和。\n",
    "\n",
    "-L2损失函数定义为：均方误差(真实减去样本的平方的和)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def L2(y, yhat):\n",
    "    loss = np.dot((y - yhat), (y - yhat).T)\n",
    "    return loss\n",
    "\n",
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L2 = \" + str(L2(yhat,y)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8da01e5a71448ea74f54d88afa8911010d1d12e23bc7e103d40d5def4a09152c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
